{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "PtKvmZx-WmUu",
    "outputId": "0ce2a9eb-ee0c-4d4a-d750-10fb1e274835"
   },
   "outputs": [],
   "source": [
    "#@title Insatlling Pyorch\n",
    "\n",
    "# !pip install torch\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "bGU6NwlsXFSt"
   },
   "outputs": [],
   "source": [
    "#@title Import Dependencies\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "_bNfVLRUYqZA"
   },
   "outputs": [],
   "source": [
    "#@title Define Hyperparameters\n",
    "\n",
    "input_size = 784 # img_size = (28,28) ---> 28*28=784 in total\n",
    "hidden_size = 500 # number of nodes at hidden layer\n",
    "num_classes = 10 # number of output classes discrete range [0,9]\n",
    "num_epochs = 20 # number of times which the entire dataset is passed throughout the model\n",
    "batch_size = 100 # the size of input data took for one iteration\n",
    "lr = 1e-3 # size of step\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import argparse\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCsBCXMwbpH5"
   },
   "outputs": [],
   "source": [
    "#@title Downloading MNIST data\n",
    "\n",
    "train_data = dsets.MNIST(root = '../../../examples/data/', train = True,\n",
    "                        transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "test_data = dsets.MNIST(root = '../../../examples/data/', train = False,\n",
    "                       transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfDPBdnYgfGp"
   },
   "outputs": [],
   "source": [
    "#@title Loading the data\n",
    "\n",
    "train_gen = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                             batch_size = batch_size,\n",
    "                                             shuffle = True)\n",
    "\n",
    "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
    "                                      batch_size = batch_size, \n",
    "                                      shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fL-YXTvghaz_"
   },
   "outputs": [],
   "source": [
    "#@title Define model class\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3EPEqbjjfAT"
   },
   "outputs": [],
   "source": [
    "#@title Build the model\n",
    "\n",
    "net = Net()\n",
    "if torch.cuda.is_available():\n",
    "  net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePLIwvAFj2zH"
   },
   "outputs": [],
   "source": [
    "#@title Define loss-function & optimizer\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam( net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u75Xa5VckuTH"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [20, 1, 5, 5], but got 2-dimensional input of size [100, 784] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-98fa1ba12c5e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/envs/obj_detection/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/envs/obj_detection/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [20, 1, 5, 5], but got 2-dimensional input of size [100, 784] instead"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#@title Training the model\n",
    "\n",
    "for epoch in range(10):\n",
    "  for i ,(images,labels) in enumerate(train_gen):\n",
    "    images = Variable(images.view(-1,28*28)).cuda()\n",
    "    labels = Variable(labels).cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = net.forward(images)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 300 == 0:\n",
    "      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' % \n",
    "            (epoch+1, num_epochs, i+1, len(train_data)//batch_size, loss.data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DTPvMW5jHB9X",
    "outputId": "9f713c0f-abfb-4efa-af9f-fd7c3a923e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 98.000 %\n"
     ]
    }
   ],
   "source": [
    "#@title Evaluating the accuracy of the model\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_gen:\n",
    "  images = Variable(images.view(-1,28*28)).cuda()\n",
    "  labels = labels.cuda()\n",
    "  \n",
    "  output = net(images)\n",
    "  _, predicted = torch.max(output,1)\n",
    "  correct += (predicted == labels).sum()\n",
    "  total += labels.size(0)\n",
    "\n",
    "print('Accuracy of the model: %.3f %%' %((100*correct)/(total+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nNwYE0B6OUfv"
   },
   "source": [
    "## Understanding the output\n",
    "\n",
    "Essa parte do código:\n",
    "\n",
    "```python\n",
    "for images,labels in test_gen:\n",
    "```\n",
    "\n",
    "Atribui a saida de test_gen às variaveis `images` e `labels`.\n",
    "Assim, a cada iteração do loop, o script compara a predição da rede com o número real.\n",
    "Como definimos `batch size = 100`, ele faz 100 predições a cada iteração.\n",
    "\n",
    "Abaixo, vamos explorar as saídas para exemplos específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c6J1qaW2Pe0y",
    "outputId": "946933ea-f63b-4df4-9a55-95e0fb0a7f21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Hi8gjW2Phy_"
   },
   "source": [
    "A variável `test_gen` tem 100 batches com 100 imagens cada, totalizando `100 x 100 = 10000` imagens. \n",
    "Vamos atribuir um batch à variável `one_iter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kAsquVhwOgwe",
    "outputId": "cbb18dd2-ddee-47d2-f657-0f9ba6692b91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_iter = list(test_gen)[1]\n",
    "len(one_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgQqmjo8QMsc"
   },
   "source": [
    "A variável `one_iter` tem tamanho 2 pois o indice 0 contém as imagens do batch e o indice 1 contém as labels.\n",
    "Vamos criar então as variáveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "h-DH6H3c_v78",
    "outputId": "06a4fbb6-db3a-4827-d03b-97b6607533cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "image_batch = one_iter[0]\n",
    "label_batch = one_iter[1]\n",
    "print(len(image_batch))\n",
    "print(len(label_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngIdakvTRQiZ"
   },
   "source": [
    "Ambas tem tamanho 100 pois são 100 imagens em um batch, com suas respectivas 100 labels.\n",
    "Agora vamos atribuir uma unica imagem e sua label às variáveis `image` e `label` respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kf-yfLuUR4eE"
   },
   "outputs": [],
   "source": [
    "img_index = 15\n",
    "image = image_batch[img_index]\n",
    "label = label_batch[img_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YykWJSHaRsla"
   },
   "source": [
    "\n",
    "Como a rede ja foi treinada, podemos ver a saida de uma previsão \"passando\" uma imagem pela rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yf_e0RIyQ_bC"
   },
   "outputs": [],
   "source": [
    "output = net(Variable(image.view(-1,28*28)).cuda())\n",
    "pred = int(torch.max(output,1)[1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "9E5M-K7IGowq",
    "outputId": "4f6651be-ac28-4d49-8d01-ac532a0e276b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A label correta é 4 e a previsão da rede foi 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Variable(image.view(-1,28*28)).cuda()\n",
    "plt.imshow(np.array(img.cpu()).reshape((28,28)),cmap = 'gray')\n",
    "print(\"A label correta é \" + str(int(label.cpu())) + \\\n",
    "      \" e a previsão da rede foi \" + str(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zxQbGh-aBRC3"
   },
   "outputs": [],
   "source": [
    "output_batch = net(Variable(image_batch.view(-1,28*28)).cuda())\n",
    "output_batch_tensor = torch.max(output_batch,1)[1].cpu()\n",
    "preds_batch = [int(x) for x in output_batch_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "vX0mVOSkCpKY",
    "outputId": "46cb39c4-fce5-43ee-f036-9a449ca05c82",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 0, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7, 3, 9, 7, 4, 4, 4, 9, 2, 5, 4, 7, 6, 7, 9, 0, 5, 8, 5, 6, 6, 5, 7, 8, 1, 0, 1, 6, 4, 6, 7, 3, 1, 7, 1, 8, 2, 0, 9, 9, 9, 5, 5, 1, 5, 6, 0, 3, 4, 4, 6, 5, 4, 6, 5, 4, 5, 1, 4, 4, 7, 2, 3, 2, 7, 1, 8, 1, 8, 1, 8, 5, 0, 8, 9, 2, 5, 0, 1, 1, 1, 0, 9, 0, 3, 1, 6, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "print(preds_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "2r4qxaL3T7Bi",
    "outputId": "da891978-0136-48cb-e001-c55071312761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 0, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7, 3, 9, 7, 4, 4, 4, 9, 2, 5, 4, 7, 6, 7, 9, 0, 5, 8, 5, 6, 6, 5, 7, 8, 1, 0, 1, 6, 4, 6, 7, 3, 1, 7, 1, 8, 2, 0, 2, 9, 9, 5, 5, 1, 5, 6, 0, 3, 4, 4, 6, 5, 4, 6, 5, 4, 5, 1, 4, 4, 7, 2, 3, 2, 7, 1, 8, 1, 8, 1, 8, 5, 0, 8, 9, 2, 5, 0, 1, 1, 1, 0, 9, 0, 3, 1, 6, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "target_batch = [int(x) for x in label_batch.cpu()]\n",
    "print(target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "pR2oOr8PU_1y",
    "outputId": "e18e1bf1-0b9d-4e5a-e6fe-59f145ba5bed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output_batch_tensor != label_batch).nonzero()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Pytorch MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "obj_detection",
   "language": "python",
   "name": "obj_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
