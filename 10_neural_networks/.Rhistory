install.packages("tensorflow")
library(tensorflow)
datasets <- tf$contrib$learn$datasets
install_tensorflow()
install.packages('neuralnet')
# creating training data set
TKS=c(20,10,30,20,80,30)
CSS=c(90,20,40,50,50,80)
Placed=c(1,0,0,0,1,1)
# Here, you will combine multiple columns or features into a single set of data
df=data.frame(TKS,CSS,Placed)
df
# load library
library(neuralnet)
# fit neural network
nn=neuralnet(Placed~TKS+CSS,data=df, hidden=3,act.fct = "logistic",
linear.output = FALSE)
plot(nn)
getwd()
# dividend info -----------------------------------------------------------
setwd('./repos/fa084-2019-1S/10_neural_networks/')
df = read.csv('~/data/di')
head(df)
head(df)
df = read.csv('data/dividendinfo.csv')
head(df)
head(df)
maxmindf <- as.data.frame(lapply(mydata, normalize))
normdf <- as.data.frame(lapply(mydata, normalize))
head(normdf)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
normdf <- as.data.frame(lapply(mydata, normalize))
head(normdf)
normdf <- as.data.frame(lapply(df, normalize))
head(normdf)
# Training and Test Data
trainset <- maxmindf[1:160, ]
testset <- maxmindf[161:200, ]
# Training and Test Data
trainset <- normdf[1:160, ]
testset <- normdf[161:200, ]
nn <- neuralnet(dividend ~ fcfps + earnings_growth + de + mcap + current_ratio, data=trainset, hidden=c(2,1), linear.output=FALSE, threshold=0.01)
nn$result.matrix
plot(nn)
plot(nn)
plot(nn)
plot(nn)
plot(nn)
setwd("~/data/Aula10/codes")
install.packages("RSNNS")
library(tidyverse)
dat = read.csv('../data/fa084_dados_cana_acucar.csv', row.names = 1)
dat[c('FertDmt','TextDmt')] = lapply(dat[c('FertDmt','TextDmt')],
as.factor)
#identificar as colunas que sao numericas
is_num = colnames(dat)[sapply(dat, is.numeric)]
dat = read.csv('../data/fa084_dados_cana_acucar.csv', row.names = 1)
dat[c('FertDmt','TextDmt')] = lapply(dat[c('FertDmt','TextDmt')],
as.factor)
#identificar as colunas que sao numericas
is_num = colnames(dat)[sapply(dat, is.numeric)]
dat = as.data.frame(model.matrix(~. -1, dat))
set.seed(1)
id_train = sample(nrow(dat), 2*nrow(dat)/3)
dat_train = dat[id_train, ]
dat_test = dat[-id_train, ]
create_fold_index = function(nrows, folds){
k_index = rep(1:folds, ceiling(nrows/folds))
k_index = k_index[1:nrows]
k_index = sample(k_index)
return(k_index)
}
k_fold_index = create_fold_index(nrow(dat_train), 10)
#  dataframe para avaliacao --------------------------------
if(file.exists("../data/tune_ann.RData") == FALSE){
tune_ann = data.frame(expand.grid(fold = 1:10,
size = seq(from = 15, to = 20, by = 5),
maxit = seq(from = nrow(dat_train), to = 3*nrow(dat_train),
by = nrow(dat_train)),
n = seq(from = 0.3, to = 0.6, by = 0.1),
dmax = c(0, 0.1, 0.02)))
tune_ann$mae = NA
a = 1
} else{
tune_ann = get(load("../data/tune_ann.RData"))
a = tail(which(is.na(tune_ann$mae) == FALSE), n =1) + 1
}
#  estrutura recursiva para validacao cruzada --------------------------------
for(i in a:nrow(tune_ann)){
ti = Sys.time()
fold = tune_ann$fold[i]
split_train = dat_train[k_fold_index != fold, ]
split_test= dat_train[k_fold_index == fold, ]
split_center = apply(split_train[is_num], 2 , min)
split_scale = apply(split_train[is_num], 2 , max) - split_center
split_train[is_num] = scale(split_train[is_num],
center = split_center,
scale = split_scale)
split_test[is_num] = scale(split_test[is_num],
center = split_center,
scale = split_scale)
tch_pos = grep('TCH', colnames(split_train))
#modelar
m = mlp(split_train[,-tch_pos], split_train[,tch_pos],
size = c(tune_ann$size[i],tune_ann$size[i]),
maxit = tune_ann$maxit[i],
learnFunc = "Std_Backpropagation",
learnFuncParams = c(tune_ann$n[i],tune_ann$dmax[i]))
t0 = Sys.time()
ypred = as.numeric(predict(m, split_test[,-tch_pos]))
tune_ann$mae[i] = mean(abs(ypred - split_test[, tch_pos]))
print(t0 - ti)
save(tune_ann, file = "../data/tune_ann.RData")
}
#install.packages('RSNNS')
library(RSNNS)
#  estrutura recursiva para validacao cruzada --------------------------------
for(i in a:nrow(tune_ann)){
ti = Sys.time()
fold = tune_ann$fold[i]
split_train = dat_train[k_fold_index != fold, ]
split_test= dat_train[k_fold_index == fold, ]
split_center = apply(split_train[is_num], 2 , min)
split_scale = apply(split_train[is_num], 2 , max) - split_center
split_train[is_num] = scale(split_train[is_num],
center = split_center,
scale = split_scale)
split_test[is_num] = scale(split_test[is_num],
center = split_center,
scale = split_scale)
tch_pos = grep('TCH', colnames(split_train))
#modelar
m = mlp(split_train[,-tch_pos], split_train[,tch_pos],
size = c(tune_ann$size[i],tune_ann$size[i]),
maxit = tune_ann$maxit[i],
learnFunc = "Std_Backpropagation",
learnFuncParams = c(tune_ann$n[i],tune_ann$dmax[i]))
t0 = Sys.time()
ypred = as.numeric(predict(m, split_test[,-tch_pos]))
tune_ann$mae[i] = mean(abs(ypred - split_test[, tch_pos]))
print(t0 - ti)
save(tune_ann, file = "../data/tune_ann.RData")
}
plot(nn)
install.packages('neuralnet')
# creating training data set
TKS=c(20,10,30,20,80,30)
CSS=c(90,20,40,50,50,80)
Placed=c(1,0,0,0,1,1)
# Here, you will combine multiple columns or features into a single set of data
df=data.frame(TKS,CSS,Placed)
df
# fit neural network
nn=neuralnet(Placed~TKS+CSS,data=df, hidden=3,act.fct = "logistic",
linear.output = FALSE)
plot(nn)
plot(nn)
Predict$net.result
Predict=compute(nn,test)
Predict$net.result
TKS=c(30,40,85)
CSS=c(85,50,40)
test=data.frame(TKS,CSS)
Predict=compute(nn,test)
# fit neural network
nn=neuralnet(Placed~TKS+CSS,data=df, hidden=3,act.fct = "logistic",
linear.output = FALSE)
plot(nn)
TKS=c(30,40,85)
CSS=c(85,50,40)
test=data.frame(TKS,CSS)
Predict=compute(nn,test)
normdf <- as.data.frame(lapply(df, normalize))
TKS=c(30,40,85)
CSS=c(85,50,40)
test=data.frame(TKS,CSS)
Predict$net.result
compute(nn,test)
Predict=neuralnet::compute(nn,test)
Predict$net.result
library(devtools)
source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')
plot.nnet(nn)
plot.nnet(nn)
library(neuralnet)
# fit neural network
nn=neuralnet(Placed~TKS+CSS,data=df, hidden=3,act.fct = "logistic",
linear.output = FALSE)
plot(nn)
TKS=c(30,40,85)
CSS=c(85,50,40)
test=data.frame(TKS,CSS)
Predict=neuralnet::compute(nn,test)
Predict$net.result
plot.nnet(nn)
#install.packages('neuralnet')
library(devtools)
source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')
# creating training data set
TKS=c(20,10,30,20,80,30)
plot.nnet(nn)
plot.nnet(nn)
nn
nn$weights
plot.nnet(nn)
plot(nn)
# dividend info -----------------------------------------------------------
setwd('./repos/fa084-2019-1S/10_neural_networks/')
# dividend info -----------------------------------------------------------
setwd('~/repos/fa084-2019-1S/10_neural_networks/')
df = read.csv('data/dividendinfo.csv')
head(df)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
normdf <- as.data.frame(lapply(df, normalize))
head(normdf)
# Training and Test Data
trainset <- normdf[1:160, ]
testset <- normdf[161:200, ]
nn <- neuralnet(dividend ~ fcfps + earnings_growth + de + mcap + current_ratio, data=trainset, hidden=c(2,1), linear.output=FALSE, threshold=0.01)
plot(nn)
plot.nnet(nn)
plot.nnet(nn)
nn$weights
library(caret)
tune_ann
head(tune_ann)
source_url('https://gist.github.com/fawda123/6206737/raw/2e1bc9cbc48d1a56d2a79dd1d33f414213f5f1b1/gar_fun.r')
head(df)
gar.fun('dividend',nn,bar.plot=F)
gar.fun('dividend',nn$weights %>% unlist(),bar.plot=F)
library("cranlogs")
today <- as.character(as.Date(Sys.time()))
pkgs <- c('nnet', 'neuralnet', 'RSNNS', 'FCNN4R', 'AMORE', 'monmlp', 'qrnn', 'grnn')
tots <- sapply(pkgs, function(x) {
sum(cran_downloads(x, from = '2000-01-01', to = today)$count)
})
barplot(tots, ylab = 'Downloads to date')
install.packages('cranlogs')
library("cranlogs")
today <- as.character(as.Date(Sys.time()))
pkgs <- c('nnet', 'neuralnet', 'RSNNS', 'FCNN4R', 'AMORE', 'monmlp', 'qrnn', 'grnn')
tots <- sapply(pkgs, function(x) {
sum(cran_downloads(x, from = '2000-01-01', to = today)$count)
})
barplot(tots, ylab = 'Downloads to date')
install.packages('NeuralNetTools')
plotnet(nn)
library(NeuralNetTools)
plotnet(nn)
library(devtools)
source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')
source_url('https://gist.github.com/fawda123/6206737/raw/2e1bc9cbc48d1a56d2a79dd1d33f414213f5f1b1/gar_fun.r')
neuraldat
# creating training data set
TKS=c(20,10,30,20,80,30)
CSS=c(90,20,40,50,50,80)
Placed=c(1,0,0,0,1,1)
# Here, you will combine multiple columns or features into a single set of data
df=data.frame(TKS,CSS,Placed)
df
# fit neural network
nn=neuralnet(Placed~TKS+CSS,data=df, hidden=3,act.fct = "logistic",
linear.output = FALSE)
TKS=c(30,40,85)
CSS=c(85,50,40)
test=data.frame(TKS,CSS)
Predict=neuralnet::compute(nn,test)
Predict$net.result
plot(nn)
plotnet(nn)
nn$weights
gar(nn)
garson(nn)
old(nn)
olden(nn)
olden(nn)
Predict$net.result
TKS=c(30,40,85)
CSS=c(85,50,40)
test=data.frame(TKS,CSS)
Predict=neuralnet::compute(nn,test)
Predict$net.result
TKS=c(20,10,30,20,80,30)
CSS=c(90,20,40,50,50,80)
Placed=c(1,0,0,0,1,1)
# Here, you will combine multiple columns or features into a single set of data
df=data.frame(TKS,CSS,Placed)
df
# fit neural network
nn=neuralnet(Placed~TKS+CSS,data=df, hidden=3,act.fct = "logistic",
linear.output = FALSE)
TKS=c(30,40,85)
CSS=c(85,50,40)
test=data.frame(TKS,CSS)
Predict=neuralnet::compute(nn,test)
Predict$net.result
Predict$net.result
plot(nn)
plotnet(nn)
nn$weights
olden(nn)
Predict$net.result
Predict=neuralnet::compute(nn,test)
Predict$net.result
# dividend info -----------------------------------------------------------
setwd('~/repos/fa084-2019-1S/10_neural_networks/')
df = read.csv('data/dividendinfo.csv')
head(df)
df = read.csv('https://transfer.sh/pKW3B/dividend_info.csv')
head(df)
rm(df)
df = read.csv('https://transfer.sh/pKW3B/dividend_info.csv')
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
normdf <- as.data.frame(lapply(df, normalize))
head(normdf)
# Training and Test Data
trainset <- normdf[1:160, ]
testset <- normdf[161:200, ]
nn <- neuralnet(dividend ~ fcfps + earnings_growth + de + mcap + current_ratio, data=trainset, hidden=c(2,1), linear.output=FALSE, threshold=0.01)
plot(nn)
plot(nn)
plotnet(nn)
nn$weights
olden(nn)
#Test the resulting output
temp_test <- subset(testset, select = c("fcfps","earnings_growth", "de", "mcap", "current_ratio"))
head(temp_test)
nn.results <- compute(nn, temp_test)
nn.results <- neuralnet::compute(nn, temp_test)
results <- data.frame(actual = testset$dividend, prediction = nn.results$net.result)
results
results$prediction = round(results$prediction,digits = 0)
results
table(results$actual,results$prediction)
table(actual = results$actual,predicted = results$prediction)
# using caret -------------------------------------------------------------
# an old friend
Titanic
# using caret -------------------------------------------------------------
# an old friend
titanic_df = read_csv('https://transfer.sh/6xede/mod_titanic.csv')
dim(titanic)
head(titanic_df)
# using caret -------------------------------------------------------------
# an old friend
titanic_df = read_csv('https://transfer.sh/6xede/mod_titanic.csv') %>% select(-PassengerId)
head(titanic_df)
normdf <- as.data.frame(lapply(titanic_df, normalize))
head(norm_df)
head(normdf)
test_rows = sample(nrow(normdf),0.2*nrow(normdf))
test_rows = sample(nrow(normdf),0.2*nrow(normdf))
test_rows = sample(nrow(normdf),0.2*nrow(normdf))
train = normdf[-test_rows,]
test = normdf[test_rows,]
nn <- neuralnet(survived ~ ., data=trai, hidden=c(2,1), linear.output=FALSE, threshold=0.01)
nn <- neuralnet(survived ~ ., data=train, hidden=c(2,1), linear.output=FALSE, threshold=0.01)
nn <- neuralnet(Survived ~ ., data=train, hidden=c(2,1), linear.output=FALSE, threshold=0.01)
plot(nn)
plotnet(nn)
nn$weights
olden(nn)
nn.results <- neuralnet::compute(nn,test)
results <- data.frame(actual = test$Survived, prediction = nn.results$net.result)
results
results$prediction = round(results$prediction,digits = 0)
table(actual = results$actual,predicted = results$prediction)
data(iris)
TrainData <- iris[,1:4]
TrainClasses <- iris[,5]
nnetFit <- train(TrainData, TrainClasses,
method = "neuralnet",
preProcess = "range",
tuneLength = 2,
trace = FALSE,
maxit = 100)
nnetFit <- train(TrainData, TrainClasses,
method = "nlnet",
preProcess = "range",
tuneLength = 2,
trace = FALSE,
maxit = 100)
nnetFit <- train(TrainData, TrainClasses,
method = "nnet",
preProcess = "range",
tuneLength = 2,
trace = FALSE,
maxit = 100)
nnetFit <- train(Survived ~ ., data=train,
method = "nnet",
hidden=c(2,1))
nnetFit <- train(as.factor(Survived) ~ ., data=train,
method = "nnet", hidden=c(2,1))
nnetFit
nncaret = nnetFit$finalModel
plot(nncaret)
olden(nncaret)
plotnet(nncaret)
nncaret$wts
nnetFit <- train(as.factor(Survived) ~ ., data=train,
method = "neuralnet", hidden=c(2,1))
nnetFit <- train(as.factor(Survived) ~ ., data=train,
method = "neuralnet")
?neuralnet
nnetFit <- train(as.factor(Survived) ~ ., data=train,
method = "neuralnet",hidden=c(2,1), linear.output=FALSE, threshold=0.01)
nnetFit <- train(as.factor(Survived) ~ ., data=train,
method = "neuralnet",hidden=c(2,1), act.fct='logistic', threshold=0.01)
nnetFit <- train(as.factor(Survived) ~ ., data=train,
method = "RSNNS",hidden=c(2,1), act.fct='logistic', threshold=0.01)
nnetFit <- train(as.factor(Survived) ~ ., data=train,
method = "RSNN",hidden=c(2,1), act.fct='logistic', threshold=0.01)
nnetFit <- train(as.factor(Survived) ~ ., data=train,
method = "nnet",hidden=c(2,1), act.fct='logistic', threshold=0.01)
nnetFit
olden(nncaret)
plotnet(nncaret)
predict(nnetFit,test)
nn.results <- predict(nnetFit,test)
results <- data.frame(actual = test$Survived, prediction = nn.results$net.result)
results
results$prediction = round(results$prediction,digits = 0)
table(actual = results$actual,predicted = results$prediction)
nn.results <- neuralnet::compute(nn,test)
results <- data.frame(actual = test$Survived, prediction = nn.results$net.result)
results
results$prediction = round(results$prediction,digits = 0)
table(actual = results$actual,predicted = results$prediction)
results <- data.frame(actual = test$Survived, prediction = nn.results)
results
predict(nnetFit,test)
nn.results <- predict(nnetFit,test)
results <- data.frame(actual = test$Survived, prediction = nn.results)
results
results$prediction = round(results$prediction,digits = 0)
table(actual = results$actual,predicted = results$prediction)
nn.results <- neuralnet::compute(nn,test)
results <- data.frame(actual = test$Survived, prediction = nn.results$net.result)
results
results$prediction = round(results$prediction,digits = 0)
table(actual = results$actual,predicted = results$prediction)
nn.results <- neuralnet::compute(nn,test)
results <- data.frame(actual = test$Survived, prediction = nn.results$net.result)
#results
results$prediction = round(results$prediction,digits = 0)
table(actual = results$actual,predicted = results$prediction)
nn.results <- predict(nnetFit,test)
results <- data.frame(actual = test$Survived, prediction = nn.results)
results
results$prediction = round(results$prediction,digits = 0)
table(actual = results$actual,predicted = results$prediction)
nn.results <- predict(nnetFit,test)
results <- data.frame(actual = test$Survived, prediction = nn.results)
#results
#results$prediction = round(results$prediction,digits = 0)
table(actual = results$actual,predicted = results$prediction)
nn.results <- neuralnet::compute(nn,test)
results <- data.frame(actual = test$Survived, prediction = nn.results$net.result)
#results
results$prediction = round(results$prediction,digits = 0)
table(actual = results$actual,predicted = results$prediction)
#install.packages('neuralnet')
library(neuralnet)
library(NeuralNetTools)
library(caret)
library(devtools)
source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')
source_url('https://gist.github.com/fawda123/6206737/raw/2e1bc9cbc48d1a56d2a79dd1d33f414213f5f1b1/gar_fun.r')
# creating training data set
TKS=c(20,10,30,20,80,30)
CSS=c(90,20,40,50,50,80)
Placed=c(1,0,0,0,1,1)
# Here, you will combine multiple columns or features into a single set of data
df=data.frame(TKS,CSS,Placed)
df
# fit neural network
nn=neuralnet(Placed~TKS+CSS,data=df, hidden=3,act.fct = "logistic",
linear.output = FALSE)
TKS=c(30,40,85)
CSS=c(85,50,40)
test=data.frame(TKS,CSS)
Predict=neuralnet::compute(nn,test)
Predict$net.result
# fit neural network
nn=neuralnet(Placed~TKS+CSS,data=df, hidden=3,act.fct = "logistic",
linear.output = FALSE)
TKS=c(30,40,85)
CSS=c(85,50,40)
test=data.frame(TKS,CSS)
Predict=neuralnet::compute(nn,test)
Predict$net.result
# creating training data set
TKS=c(20,10,30,20,80,30)
CSS=c(90,20,40,50,50,80)
Placed=c(1,0,0,0,1,1)
# Here, you will combine multiple columns or features into a single set of data
df=data.frame(TKS,CSS,Placed)
df
# fit neural network
nn=neuralnet(Placed~TKS+CSS,data=df, hidden=3,act.fct = "logistic",
linear.output = FALSE)
TKS=c(30,40,85)
CSS=c(85,50,40)
test=data.frame(TKS,CSS)
Predict=neuralnet::compute(nn,test)
Predict$net.result
