#Carregue as bibliotecas necessarias
library(tidyverse)
library(class)
library(rpart)
library(caret)
#Funcoes utilizadas
normalizar = function(x){
(x - min(x))/(max(x) - min(x))
}
tpr = function(real,predito){
sum(predito == 1 & real == 1)/sum(real == 1)
}
fpr = function(real,predito){
sum(predito == 1 & real == 0)/sum(real == 0)
}
create_fold_index = function(nrows, folds){
k_index = rep(1:folds, ceiling(nrows/folds))
k_index = k_index[1:nrows]
k_index = sample(k_index)
return(k_index)
}
#Importe os dados ----
df = read.csv('~/data/fa084/weather_rain_tomorrow.csv')
df$RainTomorrow = as.factor(df$RainTomorrow)
#df = as.data.frame(apply(df,2,normalizar))
dim(df)
head(df)
#Divida em treino e teste
set.seed(2019)
rows_test = sample(nrow(df),0.30*nrow(df))
train = df[-rows_test,]
test = df[rows_test,]
table(test$RainTomorrow)
prop.table(table(test$RainTomorrow))
head(df)
train_knn = train
train_knn$RainTomorrow = NULL
train_label = train$RainTomorrow
test_knn = test
test_knn$RainTomorrow = NULL
test_label  = test$RainTomorrow
preds_knn = knn(train = train_knn,
test = test_knn,
cl = train_label,k = 10)
table(preds_knn,test_label)
mean(preds_knn==test_label)
tpr(test_label,preds_knn)
fpr(test_label,preds_knn)
preds_knn = knn(train = train_knn,
test = test_knn,
cl = train_label,k = 5)
table(preds_knn,test_label)
acc_knn = mean(preds_knn==test_label)
tpr_knn = tpr(test_label,preds_knn)
fpr_knn = fpr(test_label,preds_knn)
#Use cross validation com 5 folds para ajustar os hiperparâmetros especificados no script.
rpart_tune = data.frame(
expand.grid(minbucket = seq(from =25, to =100, by = 25),
cp = c(0.01, 0.1),
maxdepth = 2:4,
fold = 1:5),
acc = NA
)
cv_index = create_fold_index(nrow(train),5)
t0 = Sys.time()
for(i in 1:nrow(rpart_tune)){
fold = rpart_tune$fold[i]
split_train = train[cv_index != fold,]
split_test = train[cv_index == fold,]
m = rpart( RainTomorrow ~.,
split_train,
control = rpart.control(
minbucket = rpart_tune$minbucket[i],
maxdepth = rpart_tune$maxdepth[i],
cp = rpart_tune$cp[i]),
method='class')
t2 = Sys.time()
ypred = predict(m, split_test, type = 'class')
rpart_tune$acc[i] = mean(ypred == split_test$RainTomorrow)
}
t1 = Sys.time()
t1 - t0
aggregate(acc ~ minbucket + cp + maxdepth ,rpart_tune, mean) %>% arrange(desc(acc)) %>% head()
tree_model = rpart(RainTomorrow~.,train,
control = rpart.control(minbucket = 25,
cp = 0.01,
maxdepth = 3),
method = 'class')
preds_tree = predict(tree_model, test, type = 'class')
table(preds_tree,test_label)
acc_tree = mean(preds_tree==test_label)
tpr_tree = tpr(test_label,preds_tree)
fpr_tree = fpr(test_label,preds_tree)
#REGRESSAO LOGISTICA
logit_model = glm(RainTomorrow ~., train, family = 'binomial')
coef(logit_model)
preds_logit = as.numeric(predict(logit_model, test, type='response') > 0.5)
table(preds_logit,test_label)
acc_logit = mean(preds_logit==test_label)
tpr_logit = tpr(test_label,preds_logit)
fpr_logit = fpr(test_label,preds_logit)
aggregate(acc ~ minbucket + cp + maxdepth ,rpart_tune, mean) %>% arrange(desc(acc)) %>% head()
t0 = Sys.time()
for(i in 1:nrow(rpart_tune)){
fold = rpart_tune$fold[i]
split_train = train[cv_index != fold,]
split_test = train[cv_index == fold,]
m = rpart( RainTomorrow ~.,
split_train,
control = rpart.control(
minbucket = rpart_tune$minbucket[i],
maxdepth = rpart_tune$maxdepth[i],
cp = rpart_tune$cp[i]),
method='class')
t2 = Sys.time()
ypred = predict(m, split_test, type = 'class')
rpart_tune$acc[i] = mean(ypred == split_test$RainTomorrow)
}
t1 = Sys.time()
t1 - t0
aggregate(acc ~ minbucket + cp + maxdepth ,rpart_tune, mean) %>% arrange(desc(acc)) %>% head()
rm(list=ls())
#Carregue as bibliotecas necessarias
library(tidyverse)
library(class)
library(rpart)
library(caret)
#Funcoes utilizadas
normalizar = function(x){
(x - min(x))/(max(x) - min(x))
}
tpr = function(real,predito){
sum(predito == 1 & real == 1)/sum(real == 1)
}
fpr = function(real,predito){
sum(predito == 1 & real == 0)/sum(real == 0)
}
create_fold_index = function(nrows, folds){
k_index = rep(1:folds, ceiling(nrows/folds))
k_index = k_index[1:nrows]
k_index = sample(k_index)
return(k_index)
}
#Importe os dados ----
df = read.csv('~/data/fa084/weather_rain_tomorrow.csv')
df$RainTomorrow = as.factor(df$RainTomorrow)
#df = as.data.frame(apply(df,2,normalizar))
dim(df)
head(df)
#Divida em treino e teste
set.seed(2019)
rows_test = sample(nrow(df),0.30*nrow(df))
train = df[-rows_test,]
test = df[rows_test,]
table(test$RainTomorrow)
prop.table(table(test$RainTomorrow))
head(df)
train_knn = train
train_knn$RainTomorrow = NULL
train_label = train$RainTomorrow
test_knn = test
test_knn$RainTomorrow = NULL
test_label  = test$RainTomorrow
preds_knn = knn(train = train_knn,
test = test_knn,
cl = train_label,k = 10)
table(preds_knn,test_label)
mean(preds_knn==test_label)
tpr(test_label,preds_knn)
fpr(test_label,preds_knn)
preds_knn = knn(train = train_knn,
test = test_knn,
cl = train_label,k = 5)
table(preds_knn,test_label)
acc_knn = mean(preds_knn==test_label)
tpr_knn = tpr(test_label,preds_knn)
fpr_knn = fpr(test_label,preds_knn)
#Use cross validation com 5 folds para ajustar os hiperparâmetros especificados no script.
rpart_tune = data.frame(
expand.grid(minbucket = seq(from =25, to =100, by = 25),
cp = c(0.01, 0.1),
maxdepth = 2:4,
fold = 1:5),
acc = NA
)
cv_index = create_fold_index(nrow(train),5)
t0 = Sys.time()
for(i in 1:nrow(rpart_tune)){
fold = rpart_tune$fold[i]
split_train = train[cv_index != fold,]
split_test = train[cv_index == fold,]
m = rpart( RainTomorrow ~.,
split_train,
control = rpart.control(
minbucket = rpart_tune$minbucket[i],
maxdepth = rpart_tune$maxdepth[i],
cp = rpart_tune$cp[i]),
method='class')
t2 = Sys.time()
ypred = predict(m, split_test, type = 'class')
rpart_tune$acc[i] = mean(ypred == split_test$RainTomorrow)
}
t1 = Sys.time()
t1 - t0
aggregate(acc ~ minbucket + cp + maxdepth ,rpart_tune, mean) %>% arrange(desc(acc)) %>% head()
tree_model = rpart(RainTomorrow~.,train,
control = rpart.control(minbucket = 75,
cp = 0.01,
maxdepth = 3),
method = 'class')
preds_tree = predict(tree_model, test, type = 'class')
table(preds_tree,test_label)
acc_tree = mean(preds_tree==test_label)
tpr_tree = tpr(test_label,preds_tree)
fpr_tree = fpr(test_label,preds_tree)
#Carregue as bibliotecas necessarias
library(tidyverse)
library(class)
library(rpart)
library(caret)
#Funcoes utilizadas
normalizar = function(x){
(x - min(x))/(max(x) - min(x))
}
tpr = function(real,predito){
sum(predito == 1 & real == 1)/sum(real == 1)
}
fpr = function(real,predito){
sum(predito == 1 & real == 0)/sum(real == 0)
}
create_fold_index = function(nrows, folds){
k_index = rep(1:folds, ceiling(nrows/folds))
k_index = k_index[1:nrows]
k_index = sample(k_index)
return(k_index)
}
#Importe os dados ----
df = read.csv('~/data/fa084/weather_rain_tomorrow.csv')
df$RainTomorrow = as.factor(df$RainTomorrow)
#df = as.data.frame(apply(df,2,normalizar))
dim(df)
head(df)
#Divida em treino e teste
set.seed(2019)
rows_test = sample(nrow(df),0.30*nrow(df))
train = df[-rows_test,]
test = df[rows_test,]
table(test$RainTomorrow)
prop.table(table(test$RainTomorrow))
head(df)
train_knn = train
train_knn$RainTomorrow = NULL
train_label = train$RainTomorrow
test_knn = test
test_knn$RainTomorrow = NULL
test_label  = test$RainTomorrow
preds_knn = knn(train = train_knn,
test = test_knn,
cl = train_label,k = 10)
table(preds_knn,test_label)
mean(preds_knn==test_label)
tpr(test_label,preds_knn)
fpr(test_label,preds_knn)
preds_knn = knn(train = train_knn,
test = test_knn,
cl = train_label,k = 5)
table(preds_knn,test_label)
acc_knn = mean(preds_knn==test_label)
tpr_knn = tpr(test_label,preds_knn)
fpr_knn = fpr(test_label,preds_knn)
#Use cross validation com 5 folds para ajustar os hiperparâmetros especificados no script.
rpart_tune = data.frame(
expand.grid(minbucket = seq(from =25, to =100, by = 25),
cp = c(0.01, 0.1),
maxdepth = 2:4,
fold = 1:5),
acc = NA
)
cv_index = create_fold_index(nrow(train),5)
t0 = Sys.time()
for(i in 1:nrow(rpart_tune)){
fold = rpart_tune$fold[i]
split_train = train[cv_index != fold,]
split_test = train[cv_index == fold,]
m = rpart( RainTomorrow ~.,
split_train,
control = rpart.control(
minbucket = rpart_tune$minbucket[i],
maxdepth = rpart_tune$maxdepth[i],
cp = rpart_tune$cp[i]),
method='class')
t2 = Sys.time()
ypred = predict(m, split_test, type = 'class')
rpart_tune$acc[i] = mean(ypred == split_test$RainTomorrow)
}
t1 = Sys.time()
t1 - t0
aggregate(acc ~ minbucket + cp + maxdepth ,rpart_tune, mean) %>% arrange(desc(acc)) %>% head()
tree_model = rpart(RainTomorrow~.,train,
control = rpart.control(minbucket = 75,
cp = 0.01,
maxdepth = 3),
method = 'class')
t0 = Sys.time()
for(i in 1:nrow(rpart_tune)){
fold = rpart_tune$fold[i]
split_train = train[cv_index != fold,]
split_test = train[cv_index == fold,]
m = rpart( RainTomorrow ~.,
split_train,
control = rpart.control(
minbucket = rpart_tune$minbucket[i],
maxdepth = rpart_tune$maxdepth[i],
cp = rpart_tune$cp[i]),
method='class')
t2 = Sys.time()
ypred = predict(m, split_test, type = 'class')
rpart_tune$acc[i] = mean(ypred == split_test$RainTomorrow)
}
t1 = Sys.time()
t1 - t0
aggregate(acc ~ minbucket + cp + maxdepth ,rpart_tune, mean) %>% arrange(desc(acc)) %>% head()
gbmGrid = expand.grid(interaction.depth = c(1, 5, 9),
n.trees = c(50,100,150,200,250),
shrinkage = 0.1,
n.minobsinnode = 20)
caret_boost = train(RainTomorrow~.,
data = train, method='gbm',
trControl = trainControl(method = 'cv',number =5),tuneGrid = gbmGrid)
preds_boost = predict(caret_boost,test)
table(preds_boost,test_label)
acc_boost = mean(preds_boost==test_label)
tpr_boost = tpr(test_label,preds_boost)
fpr_boost = fpr(test_label,preds_boost)
preds_boost
caret_boost
gbmGrid = expand.grid(interaction.depth = c(1, 5, 9),
n.trees = c(50,100,150,200,250),
shrinkage = 0.1,
n.minobsinnode = 20)
caret_boost = train(RainTomorrow~.,
data = train, method='gbm',
trControl = trainControl(method = 'cv',number =5),tuneGrid = gbmGrid)
preds_boost = predict(caret_boost,test)
caret_boost
rm(list=ls())
