task = makeClassifTask(data = normdf, target = 'cardio')
task
set.seed(2019)
#A1)Defina o holdout. O argumento split corresponde a % de treino em decimal
holdout = makeResampleInstance("Holdout",task, split = 0.7)
#A2)task de treino
tsk_train = subsetTask(task, holdout$train.inds[[1]])
#A3)task de teste
tsk_test = subsetTask(task, holdout$test.inds[[1]])
#B) Defina os learners
svm_learner = makeLearner("classif.svm")
nn_learner = makeLearner('classif.neuralnet',stepmax=1000)
params_svm = makeParamSet(makeNumericParam("cost",lower = 0.1,
upper = 1),
makeNumericParam("gamma", lower = 0.1,
upper = 1))
params_nn = makeParamSet(makeIntegerVectorParam('hidden',len = 1,lower=1,upper=1))
#E) Defina o controle: RandomSearch com 50 iteracoes
tune_control = makeTuneControlRandom(maxit=10)
#F) Ajuste os parametros das duas tecnicas
t0 = Sys.time()
set.seed(2019)
tr_svm = tuneParams(svm_learner,tsk_train,cv5,list(acc),
params_svm,tune_control)
t1 = Sys.time()
t0 = Sys.time()
set.seed(2019)
tr_nn = tuneParams(nn_learner,tsk_train,cv5,list(acc),params_nn,tune_control)
t1 = Sys.time()
?neuralnet
params_nn = makeParamSet(makeIntegerVectorParam('hidden',len = 2,lower=3,upper=4))
tr_nn = tuneParams(nn_learner,tsk_train,cv5,list(acc),params_nn,tune_control)
net_learner = makeLearner('classif.neuralnet',stepmax=10000)
model = train(net_learner,task)
model = train(net_learner,tsk_train)
net_learner = makeLearner('classif.neuralnet',stepmax=100000)
r = resample(net_learner,task,resampling = makeResampleDesc(method ='CV',iters=5 ))
r = resample(net_learner,task,cv5)
tunes = tuneParams(net_learner,task,cv5,params_nn,ctrl)
tunes = tuneParams(net_learner,task,cv5,mae,params_nn,ctrl)
tunes = tuneParams(net_learner,task,cv5,mae,params_nn, control)
tunes = tuneParams(net_learner,task,cv5,mae,params_nn, tune_control)
tunes = tuneParams(net_learner,task,cv5,mae,params_nn, tune_control)
net_learner = makeLearner('classif.neuralnet',stepmax=1000)
r = resample(net_learner,task,cv5)
tunes = tuneParams(net_learner,task,cv5,mae,params_nn, tune_control)
net_learner = makeLearner('classif.neuralnet',stepmax=10000)
r = resample(net_learner,task,cv5)
r = resample(net_learner,task,cv5)
r = resample(net_learner,task,cv5)
r = resample(net_learner,task,cv5)
r = resample(net_learner,task,cv5)
r = resample(net_learner,task,cv5)
task = makeClassifTask(data=tst,target = 'cardio' )
glimpse(ts)
glimpse(tst)
model = train(net_learner,tsk_train)
r = resample(net_learner,task,cv5)
r = resample(net_learner,tsk_train,cv5)
tsk_train$env$data
tsk_train$env$data %>% glimpse()
glimpse(normdf)
#A) Crie uma task de treino (70%) e de teste. Use os procedimentos de "agora e sua vez",
#da aula 11(11_mlr_svm_base.html, baixe o arquivo e abra no navegador).
#Complete as lacunas abaixo. Crie mais variaveis se julgar adequado.
task = makeClassifTask(data = normdf, target = 'cardio')
tsk_train$env$data %>% glimpse()
task$env$data %>% glimpse()
#B) Converta a coluna cardio para factor
normdf = mutate(normdf,cardio=as.factor(cardio))
#A) Crie uma task de treino (70%) e de teste. Use os procedimentos de "agora e sua vez",
#da aula 11(11_mlr_svm_base.html, baixe o arquivo e abra no navegador).
#Complete as lacunas abaixo. Crie mais variaveis se julgar adequado.
task = makeClassifTask(data = normdf, target = 'cardio')
task
set.seed(2019)
#A1)Defina o holdout. O argumento split corresponde a % de treino em decimal
holdout = makeResampleInstance("Holdout",task, split = 0.7)
#A2)task de treino
tsk_train = subsetTask(task, holdout$train.inds[[1]])
#A3)task de teste
tsk_test = subsetTask(task, holdout$test.inds[[1]])
#B) Defina os learners
svm_learner = makeLearner("classif.svm")
nn_learner = makeLearner('classif.neuralnet',stepmax=1000)
nn_learner = makeLearner('classif.nnet')
params_svm = makeParamSet(makeNumericParam("cost",lower = 0.1,
upper = 1),
makeNumericParam("gamma", lower = 0.1,
upper = 1))
params_nn = makeParamSet(makeIntegerParam('size',lower=2,upper=5))
#E) Defina o controle: RandomSearch com 50 iteracoes
tune_control = makeTuneControlRandom(maxit=10)
#F) Ajuste os parametros das duas tecnicas
t0 = Sys.time()
set.seed(2019)
tr_svm = tuneParams(svm_learner,tsk_train,cv5,list(acc),
params_svm,tune_control)
t1 = Sys.time()
t0 = Sys.time()
set.seed(2019)
tr_nn = tuneParams(nn_learner,tsk_train,cv5,list(acc),params_nn,tune_control)
t1 = Sys.time()
#G) Quais os melhores parâmetros de cada tecnica?
tr_svm$x
tr_nn$x
#H) Use setHyperPars para ajustar os parametros encontrados aos learners criados
tuned_svm = setHyperPars(svm_learner,par.vals = tr_svm$x)
tuned_nn = setHyperPars(nn_learner,par.vals = tr_nn$x)
#I) Treine no conjunto completo com a funcao train()
tuned_svm = train(tuned_svm, tsk_train)
tuned_nn = train(tuned_nn, tsk_train)
#J) Faca as predicoes na task de teste. Qual a acuracia dos dois modelos?
preds_svm = predict(tuned_svm,tsk_test)
preds_nn = predict(tuned_nn,tsk_test)
#K) Preencha as matrizes de confusao de cada modelo. Use calculateConfusionMatrix()
#nas predicoes acima.
calculateConfusionMatrix(preds_svm)
calculateConfusionMatrix(preds_nn)
task = makeClassifTask(data = normdf, target = 'cardio')
task
set.seed(2019)
#A1)Defina o holdout. O argumento split corresponde a % de treino em decimal
holdout = makeResampleInstance("Holdout",task, split = 0.7)
#A2)task de treino
tsk_train = subsetTask(task, holdout$train.inds[[1]])
#A3)task de teste
tsk_test = subsetTask(task, holdout$test.inds[[1]])
#B) Defina os learners
svm_learner = makeLearner("classif.svm")
nn_learner = makeLearner('classif.nnet')
#C) Defina os parametros a serem ajustados.
#SVM:
#Custo é um hiperparametro numerico que deve variar entre 0.1 e 1.
#Gamma é um hiperparametro numerico que deve variar entre 0.1 e 2.
#NN:
#Size é um hiperparametro inteiro que deve variar de 2 a 5.
params_svm = makeParamSet(makeNumericParam("cost",lower = 0.1,
upper = 1),
makeNumericParam("gamma", lower = 0.1,
upper = 1))
params_nn = makeParamSet(makeIntegerParam('size',lower=2,upper=5))
#D) Escolha um dos hiperparametros da SVM e explique seu significado
#E) Defina o controle: RandomSearch com 50 iteracoes
tune_control = makeTuneControlRandom(maxit=10)
#F) Ajuste os parametros das duas tecnicas
t0 = Sys.time()
set.seed(2019)
tr_svm = tuneParams(svm_learner,tsk_train,cv5,list(acc),
params_svm,tune_control)
t1 = Sys.time()
t0 = Sys.time()
set.seed(2019)
tr_nn = tuneParams(nn_learner,tsk_train,cv5,list(acc),params_nn,tune_control)
t1 = Sys.time()
#G) Quais os melhores parâmetros de cada tecnica?
tr_svm$x
tr_nn$x
#H) Use setHyperPars para ajustar os parametros encontrados aos learners criados
tuned_svm = setHyperPars(svm_learner,par.vals = tr_svm$x)
tuned_nn = setHyperPars(nn_learner,par.vals = tr_nn$x)
#I) Treine no conjunto completo com a funcao train()
tuned_svm = train(tuned_svm, tsk_train)
tuned_nn = train(tuned_nn, tsk_train)
#J) Faca as predicoes na task de teste. Qual a acuracia dos dois modelos?
preds_svm = predict(tuned_svm,tsk_test)
preds_nn = predict(tuned_nn,tsk_test)
#K) Preencha as matrizes de confusao de cada modelo. Use calculateConfusionMatrix()
#nas predicoes acima.
calculateConfusionMatrix(preds_svm)
calculateConfusionMatrix(preds_nn)
task = makeClassifTask(data = normdf, target = 'cardio')
task
set.seed(2019)
#A1)Defina o holdout. O argumento split corresponde a % de treino em decimal
holdout = makeResampleInstance("Holdout",task, split = 0.7)
#A2)task de treino
tsk_train = subsetTask(task, holdout$train.inds[[1]])
#A3)task de teste
tsk_test = subsetTask(task, holdout$test.inds[[1]])
#B) Defina os learners
svm_learner = makeLearner("classif.svm")
nn_learner = makeLearner('classif.nnet')
#C) Defina os parametros a serem ajustados.
#SVM:
#Custo é um hiperparametro numerico que deve variar entre 0.1 e 1.
#Gamma é um hiperparametro numerico que deve variar entre 0.1 e 2.
#NN:
#Size é um hiperparametro inteiro que deve variar de 2 a 5.
params_svm = makeParamSet(makeNumericParam("cost",lower = 0.1,
upper = 1),
makeNumericParam("gamma", lower = 0.1,
upper = 1))
params_nn = makeParamSet(makeIntegerParam('size',lower=2,upper=5))
#D) Escolha um dos hiperparametros da SVM e explique seu significado
#E) Defina o controle: RandomSearch com 50 iteracoes
tune_control = makeTuneControlRandom(maxit=50)
#F) Ajuste os parametros das duas tecnicas
t0 = Sys.time()
set.seed(2019)
tr_svm = tuneParams(svm_learner,tsk_train,cv5,list(acc),
params_svm,tune_control)
t1 = Sys.time()
t0 = Sys.time()
set.seed(2019)
tr_nn = tuneParams(nn_learner,tsk_train,cv5,list(acc),params_nn,tune_control)
t1 = Sys.time()
#G) Quais os melhores parâmetros de cada tecnica?
tr_svm$x
tr_nn$x
#H) Use setHyperPars para ajustar os parametros encontrados aos learners criados
tuned_svm = setHyperPars(svm_learner,par.vals = tr_svm$x)
tuned_nn = setHyperPars(nn_learner,par.vals = tr_nn$x)
#I) Treine no conjunto completo com a funcao train()
tuned_svm = train(tuned_svm, tsk_train)
tuned_nn = train(tuned_nn, tsk_train)
#J) Faca as predicoes na task de teste. Qual a acuracia dos dois modelos?
preds_svm = predict(tuned_svm,tsk_test)
preds_nn = predict(tuned_nn,tsk_test)
#K) Preencha as matrizes de confusao de cada modelo. Use calculateConfusionMatrix()
#nas predicoes acima.
calculateConfusionMatrix(preds_svm)
calculateConfusionMatrix(preds_nn)
#F) Ajuste os parametros das duas tecnicas
t0 = Sys.time()
set.seed(2019)
tr_svm = tuneParams(svm_learner,tsk_train,cv5,list(acc),
params_svm,tune_control)
t1 = Sys.time()
t0 = Sys.time()
set.seed(2019)
tr_nn = tuneParams(nn_learner,tsk_train,cv5,list(acc),params_nn,tune_control)
t1 = Sys.time()
#G) Quais os melhores parâmetros de cada tecnica?
tr_svm$x
tr_nn$x
#H) Use setHyperPars para ajustar os parametros encontrados aos learners criados
tuned_svm = setHyperPars(svm_learner,par.vals = tr_svm$x)
tuned_nn = setHyperPars(nn_learner,par.vals = tr_nn$x)
#I) Treine no conjunto completo com a funcao train()
tuned_svm = train(tuned_svm, tsk_train)
tuned_nn = train(tuned_nn, tsk_train)
#J) Faca as predicoes na task de teste. Qual a acuracia dos dois modelos?
preds_svm = predict(tuned_svm,tsk_test)
preds_nn = predict(tuned_nn,tsk_test)
#K) Preencha as matrizes de confusao de cada modelo. Use calculateConfusionMatrix()
#nas predicoes acima.
calculateConfusionMatrix(preds_svm)
calculateConfusionMatrix(preds_nn)
#Questao Bonus ----------------------------------------------------------------
roc_svm = calculateROCMeasures(preds_svm)
#E) Defina o controle: RandomSearch com 50 iteracoes
tune_control = makeTuneControlRandom(maxit=100)
#F) Ajuste os parametros das duas tecnicas
t0 = Sys.time()
set.seed(2019)
tr_svm = tuneParams(svm_learner,tsk_train,cv5,list(acc),
params_svm,tune_control)
t1 = Sys.time()
t0 = Sys.time()
set.seed(2019)
tr_nn = tuneParams(nn_learner,tsk_train,cv5,list(acc),params_nn,tune_control)
t1 = Sys.time()
#G) Quais os melhores parâmetros de cada tecnica?
tr_svm$x
tr_nn$x
#H) Use setHyperPars para ajustar os parametros encontrados aos learners criados
tuned_svm = setHyperPars(svm_learner,par.vals = tr_svm$x)
tuned_nn = setHyperPars(nn_learner,par.vals = tr_nn$x)
#I) Treine no conjunto completo com a funcao train()
tuned_svm = train(tuned_svm, tsk_train)
tuned_nn = train(tuned_nn, tsk_train)
#J) Faca as predicoes na task de teste. Qual a acuracia dos dois modelos?
preds_svm = predict(tuned_svm,tsk_test)
preds_nn = predict(tuned_nn,tsk_test)
#K) Preencha as matrizes de confusao de cada modelo. Use calculateConfusionMatrix()
#nas predicoes acima.
calculateConfusionMatrix(preds_svm)
calculateConfusionMatrix(preds_nn)
params_svm = makeParamSet(makeNumericParam("cost",lower = 0.1,
upper = 1),
makeNumericParam("gamma", lower = 0.1,
upper = 2))
params_nn = makeParamSet(makeIntegerParam('size',lower=2,upper=5))
#E) Defina o controle: RandomSearch com 50 iteracoes
tune_control = makeTuneControlRandom(maxit=50)
#F) Ajuste os parametros das duas tecnicas
t0 = Sys.time()
set.seed(2019)
tr_svm = tuneParams(svm_learner,tsk_train,cv5,list(acc),
params_svm,tune_control)
t1 = Sys.time()
t0 = Sys.time()
set.seed(2019)
tr_nn = tuneParams(nn_learner,tsk_train,cv5,list(acc),params_nn,tune_control)
t1 = Sys.time()
#G) Quais os melhores parâmetros de cada tecnica?
tr_svm$x
tr_nn$x
#H) Use setHyperPars para ajustar os parametros encontrados aos learners criados
tuned_svm = setHyperPars(svm_learner,par.vals = tr_svm$x)
tuned_nn = setHyperPars(nn_learner,par.vals = tr_nn$x)
#I) Treine no conjunto completo com a funcao train()
tuned_svm = train(tuned_svm, tsk_train)
tuned_nn = train(tuned_nn, tsk_train)
#J) Faca as predicoes na task de teste. Qual a acuracia dos dois modelos?
preds_svm = predict(tuned_svm,tsk_test)
preds_nn = predict(tuned_nn,tsk_test)
#K) Preencha as matrizes de confusao de cada modelo. Use calculateConfusionMatrix()
#nas predicoes acima.
calculateConfusionMatrix(preds_svm)
calculateConfusionMatrix(preds_nn)
t0 = Sys.time()
set.seed(2019)
tr_nn = tuneParams(nn_learner,tsk_train,cv5,list(acc),params_nn,tune_control)
t1 = Sys.time()
tuned_nn = setHyperPars(nn_learner,par.vals = tr_nn$x)
tuned_nn = train(tuned_nn, tsk_train)
preds_nn = predict(tuned_nn,tsk_test)
calculateConfusionMatrix(preds_nn)
#K) Preencha as matrizes de confusao de cada modelo. Use calculateConfusionMatrix()
#nas predicoes acima.
calculateConfusionMatrix(preds_svm)
set.seed(2019)
#A1)Defina o holdout. O argumento split corresponde a % de treino em decimal
holdout = makeResampleInstance("Holdout",task, split = 0.7)
#A2)task de treino
tsk_train = subsetTask(task, holdout$train.inds[[1]])
#A3)task de teste
tsk_test = subsetTask(task, holdout$test.inds[[1]])
#F) Ajuste os parametros das duas tecnicas
t0 = Sys.time()
set.seed(2019)
tr_svm = tuneParams(svm_learner,tsk_train,cv5,list(acc),
params_svm,tune_control)
t1 = Sys.time()
t0 = Sys.time()
set.seed(2019)
tr_nn = tuneParams(nn_learner,tsk_train,cv5,list(acc),params_nn,tune_control)
t1 = Sys.time()
#G) Quais os melhores parâmetros de cada tecnica?
tr_svm$x
tr_nn$x
#H) Use setHyperPars para ajustar os parametros encontrados aos learners criados
tuned_svm = setHyperPars(svm_learner,par.vals = tr_svm$x)
tuned_nn = setHyperPars(nn_learner,par.vals = tr_nn$x)
#I) Treine no conjunto completo com a funcao train()
tuned_svm = train(tuned_svm, tsk_train)
tuned_nn = train(tuned_nn, tsk_train)
#J) Faca as predicoes na task de teste. Qual a acuracia dos dois modelos?
preds_svm = predict(tuned_svm,tsk_test)
preds_nn = predict(tuned_nn,tsk_test)
#K) Preencha as matrizes de confusao de cada modelo. Use calculateConfusionMatrix()
#nas predicoes acima.
calculateConfusionMatrix(preds_svm)
calculateConfusionMatrix(preds_nn)
#Questao Bonus ----------------------------------------------------------------
roc_svm = calculateROCMeasures(preds_svm)
cluster_data = as.data.frame(apply(cluster_data,2,normalize))
cluster_data = USArrests
cluster_data = as.data.frame(apply(cluster_data,2,normalize))
# Use o comando abaixo para remover os row_names de cluster_data
rownames(cluster_data) = NULL
cluster_task = makeClusterTask('cluster',cluster_data)
k_to_test = c(1:20)
wssvec = numeric()
set.seed(2019)
for(k in k_to_test){
learner = makeLearner('cluster.kmeans',centers=k,nstart=25)
tr = train(learner,cluster_task)
wss = tr$learner.model$tot.withinss
wssvec = c(wssvec,wss)
}
plot(k_to_test,wssvec,type='l')
plot(k_to_test,wssvec)
learner = makeLearner('cluster.kmeans',centers=3)
tr = train(learner,cluster_task)
clusters =tr$learner.model$cluster
#B) Crie uma coluna nova "clusters" em cluster_data, que recebe os clusters.
cluster_data$clusters = clusters
head(cluster_data)
table(cluster_data$clusters)
learner = makeLearner('cluster.kmeans',centers=4)
tr = train(learner,cluster_task)
clusters =tr$learner.model$cluster
#B) Crie uma coluna nova "clusters" em cluster_data, que recebe os clusters.
cluster_data$clusters = clusters
head(cluster_data)
table(cluster_data$clusters)
table(cluster_data$clusters)
cl_task = makeClassifTask(cluster_data,target='clusters')
#C) Temos 3 novas observacoes arquivo find_cluster.csv.
# Use uma rotina concisa para predizer a qual cluster cada uma pertence.
find_cluster = read_csv('../data/find_cluster.csv')
cl_learner = makeLearner('classif.xgboost')
cl_learner = makeLearner('classif.svm')
cl_task = makeClassifTask(cluster_data,target='clusters')
cl_task = makeClassifTask('cluster',cluster_data,target='clusters')
cl_mod = train(cl_learner,cl_task)
predict(cl_mod,find_cluster)
predict(cl_mod$learner.model,find_cluster)
learner = makeLearner('cluster.kmeans',centers=3)
tr = train(learner,cluster_task)
clusters =tr$learner.model$cluster
#B) Crie uma coluna nova "clusters" em cluster_data, que recebe os clusters.
cluster_data$clusters = clusters
head(cluster_data)
table(cluster_data$clusters)
#C) Temos 3 novas observacoes arquivo find_cluster.csv.
# Use uma rotina concisa para predizer a qual cluster cada uma pertence.
find_cluster = read_csv('../data/find_cluster.csv')
cl_learner = makeLearner('classif.svm')
cl_task = makeClassifTask('cluster',cluster_data,target='clusters')
cl_mod = train(cl_learner,cl_task)
predict(cl_mod$learner.model,find_cluster)
learner = makeLearner('cluster.kmeans',centers=4)
tr = train(learner,cluster_task)
clusters =tr$learner.model$cluster
#B) Crie uma coluna nova "clusters" em cluster_data, que recebe os clusters.
cluster_data$clusters = clusters
head(cluster_data)
table(cluster_data$clusters)
k_to_test = c(1:20)
wssvec = numeric()
set.seed(2019)
for(k in k_to_test){
learner = makeLearner('cluster.kmeans',centers=k,nstart=25)
tr = train(learner,cluster_task)
wss = tr$learner.model$tot.withinss
wssvec = c(wssvec,wss)
}
plot(k_to_test,wssvec)
learner = makeLearner('cluster.kmeans',centers=4)
tr = train(learner,cluster_task)
clusters =tr$learner.model$cluster
clusters
table(cluster_data$clusters)
cluster_data %>% group_by(clusters) %>% summarise_all(mean)
cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>%
select(-cluster) %>% write_csv('../data/find_cluster.csv')
cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>%
select(-cluster) %>% write_csv('../data/find_cluster.csv')
cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>%
select(-clusters) %>% write_csv('../data/find_cluster.csv')
#C) Temos 3 novas observacoes arquivo find_cluster.csv.
# Use uma rotina concisa para predizer a qual cluster cada uma pertence.
find_cluster = read_csv('../data/find_cluster.csv')
cl_learner = makeLearner('classif.svm')
cl_task = makeClassifTask('cluster',cluster_data,target='clusters')
cl_mod = train(cl_learner,cl_task)
predict(cl_mod$learner.model,find_cluster)
cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>% sample_n(4)
cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>% sample_n(4) %>%
select(-clusters) %>% write_csv('../data/find_cluster.csv')
#C) Temos 3 novas observacoes arquivo find_cluster.csv.
# Use uma rotina concisa para predizer a qual cluster cada uma pertence.
find_cluster = read_csv('../data/find_cluster.csv')
cl_learner = makeLearner('classif.svm')
cl_task = makeClassifTask('cluster',cluster_data,target='clusters')
cl_mod = train(cl_learner,cl_task)
predict(cl_mod$learner.model,find_cluster)
predict(cl_mod$learner.model,find_cluster) %>% unlist
predict(cl_mod$learner.model,find_cluster) %>% unlist
predict(cl_mod$learner.model,find_cluster) %>% unname()
set.seed(2019)
cluster_data = cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>% sample_n(4)
cluster_data
cluster_data = cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>% sample_n(4)
cluster_data
set.seed(2019)
cluster_data = cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>% sample_n(4)
cluster_data
cluster_data = cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>% sample_n(4)
cluster_data
cluster_data = cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>% sample_n(4)
cluster_data
set.seed(2019)
cluster_data = cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>% sample_n(4)
cluster_data
cluster_data %>%
select(-clusters) %>% write_csv('../data/find_cluster.csv')
#C) Temos 3 novas observacoes arquivo find_cluster.csv.
# Use uma rotina concisa para predizer a qual cluster cada uma pertence.
find_cluster = read_csv('../data/find_cluster.csv')
cl_learner = makeLearner('classif.svm')
cl_task = makeClassifTask('cluster',cluster_data,target='clusters')
cl_mod = train(cl_learner,cl_task)
predict(cl_mod$learner.model,find_cluster) %>% unname()
cluster_data = cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>% sample_n(4)
cluster_data
cluster_data %>%
select(-clusters) %>% write_csv('../data/find_cluster.csv')
#C) Temos novas observacoes arquivo find_cluster.csv.
# Novos dados de crimes de regioes.
# Use uma rotina concisa para atribuir cada observacao a um cluster.
find_cluster = read_csv('../data/find_cluster.csv')
cl_learner = makeLearner('classif.svm')
cl_task = makeClassifTask('cluster',cluster_data,target='clusters')
cl_mod = train(cl_learner,cl_task)
predict(cl_mod$learner.model,find_cluster) %>% unname()
cluster_data = cluster_data %>% group_by(clusters) %>% summarise_all(mean) %>% sample_n(4)
cluster_data
cluster_data %>%
select(-clusters) %>% write_csv('../data/find_cluster.csv')
#C) Temos novas observacoes arquivo find_cluster.csv.
# Novos dados de crimes de regioes.
# Use uma rotina concisa para atribuir cada observacao a um cluster.
find_cluster = read_csv('../data/find_cluster.csv')
cl_learner = makeLearner('classif.svm')
cl_task = makeClassifTask('cluster',cluster_data,target='clusters')
cl_mod = train(cl_learner,cl_task)
predict(cl_mod$learner.model,find_cluster) %>% unname()
