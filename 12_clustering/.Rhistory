#use cross validation com 5 folds como estrategia de amostragem
rdesc =  makeResampleDesc("CV", iters = 5)
#execute o set.seed junto com o tree_result para obert sempre o mesmo resultado
set.seed(2019)
tree_tune = tuneParams(tree_learner,
task = train_task,
resampling = rdesc,
par.set = tree_ps,
control = ctrl,
show.info=F)
tree_tune
#execute o set.seed junto com o knn_tune para obert sempre o mesmo resultado
set.seed(2019)
knn_tune = tuneParams(knn_learner,
task = train_task,
resampling = rdesc,
par.set = knn_ps,
control = ctrl,
show.info=F)
knn_tune
#execute o set.seed junto com o knn_tune para obter sempre o mesmo resultado
#complete o argumento learner com o learner correto
set.seed(2019)
knn_tune = tuneParams(knn_learner,
task = train_task,
resampling = rdesc,
par.set = knn_ps,
control = ctrl,
show.info=F)
knn_tune
#6. A melhor combinacao de atributos para a arvore é
minsplit =
maxdepth =
#7. O melhor k para o knn é
k =
#Q8 -----
#Agora vamos treinar o learner com os modelos ajustados
tuned_tree = makeLearner('classif.rpart', maxdepth = 4, minsplit = 10)
tuned_knn = makeLearner('classif.knn',k = 9)
#As linhas abaixo treinam o modelo no conjunto de teste (614 observações)
#com os parametros ajustados acima, em tuned_tree e tuned_knn
tree_model = train(tuned_tree, classif_task)
knn_model = train(tuned_knn, classif_task)
#As linhas abaixo treinam o modelo no conjunto de teste (614 observações)
#com os parametros ajustados acima, em tuned_tree e tuned_knn
tree_model = train(tuned_tree, train_task)
knn_model = train(tuned_knn, train_task)
#crie uma task agora usando o conjunto 'test' em data
test_task = makeClassifTask(id = 'test_models', data = test, target='diabetes',positive = 'pos')
#A linha abaixo faz as predicoes no conjunto de teste
tree_preds = predict(tree_model,test_task)
#faca o mesmo com knn
knn_preds = predict(knn_model, test_task)
#Abaixo, mostramos a matrix de confusao para a arvore
calculateConfusionMatrix(tree_preds)
#Abaixo, mostre a matrix de confusao para o modelo com knn
calculateConfusionMatrix(knn_preds)
library(tidyverse)
library(mlr)
library(mlbench)
library(rpart)
library(rpart.plot)
#Carregue o conjunto de dados
data(PimaIndiansDiabetes)
df = PimaIndiansDiabetes
#use ?PimaIndiansDiabetes
#execute a linha abaixo para ver a descrição do conjunto de dados
?PimaIndiansDiabetes
# Verifique as dimensões e as primeiras linhas
dim(df)
head(df)
#vamos comparar o desempenho de árvores de decisão vs knn para prever
#se o paciente tem diabetes ou não
#1. Esta é uma tarefa de classificação ou regressão?
#2. Quantos atributos preditores vamos usar?
#3. Qual a mediana do número de vezes que a paciente engravidou para pacientes com diabetes e sem diabetes?
df %>% group_by(diabetes) %>% summarise(preg = median(pregnant), medAge = mean(age))
#Q4 -----
#Normalize os dados entre 0 e 1 com a função "normalizeFeatures()" do pacote mlr.
#Complete o method e range abaixo, como visto na aula 4
normdf = normalizeFeatures(df, method = "range", range = c(0,1))
head(normdf)
#4. Quantos pacientes temos no dataset com diabetes pos e diabetes neg?
table(normdf$diabetes)
#Separar em treino e teste -----
#numero de observacoes:
n_observations = nrow(normdf)
#porcentagem de observacoes para treino:
train_percent  = 2/3
#id das observacoes para treino, lembre de selecionar e executar as duas linhas abaixo juntas,
#para ter sempre o mesmo resultado
set.seed(2019)
train_id = sample(n_observations, train_percent * n_observations)
#separe em treino e teste, a funcao slice é como filter() mas usa os ids numéricos e não condicoes lógicas
train = normdf %>% slice(train_id)
test = normdf %>% slice(-train_id)
dim(train) #deve ser 614
dim(test) #deve ser 154
#Q5 -----
#Crie a tarefa de classificação:
#complete os argumentos data, target e positive
#use os dados de treino separados acima
#o argumento positive deve conter a classe que queremos considerar positiva, nesse caso é a classe 'pos'
train_task = makeClassifTask(id = 'tree_vs_knn', data = train, target='diabetes',positive = 'pos')
#execute a linha abaixo para descricao da tarefa
train_task
#5.Marque as alternativas corretas:
# 8 colunas do conjunto de dados são numericas
# A variavel meta é binária
# A quantidade de pacientes com diabetes é menos de 50% do que a quantidade de não diabéticos no conjunto de treino
# Nenhuma coluna do conjunto de dados é um fator
#Q7 ----
#Crie um learner para árvore e outro para knn usando os
#classif das aulas 3 e 4, respectivamente
tree_learner = makeLearner("classif.rpart")
knn_learner = makeLearner("classif.knn")
#ajuste da arvore
#vamos ajustar os hiperparametros "maxdepth" e "minsplit"
#use o limite inferior de maxdepth como 2 e superior, 5
#use o limite inferior de minsplit como 2 e superior 10
tree_ps = makeParamSet(
makeIntegerParam('maxdepth', lower = 2, upper = 5),
makeIntegerParam('minsplit', lower = 2, upper = 10))
#ajustar o k do knn
#inferiror = 3 e superior = 15
knn_ps = makeParamSet(
makeIntegerParam('k', lower = 3, upper = 15))
#estrategia de controle: 40 iteracoes com grid search
ctrl = makeTuneControlGrid(resolution = 40L)
#use cross validation com 5 folds como estrategia de amostragem
rdesc =  makeResampleDesc("CV", iters = 5)
#execute o set.seed junto com o tree_result para obert sempre o mesmo resultado
set.seed(2019)
tree_tune = tuneParams(tree_learner,
task = train_task,
resampling = rdesc,
par.set = tree_ps,
control = ctrl,
show.info=F)
tree_tune
#execute o set.seed junto com o knn_tune para obert sempre o mesmo resultado
set.seed(2019)
knn_tune = tuneParams(knn_learner,
task = train_task,
resampling = rdesc,
par.set = knn_ps,
control = ctrl,
show.info=F)
knn_tune
#6. A melhor combinacao de atributos para a arvore é
minsplit =
maxdepth =
#7. O melhor k para o knn é
k =
#Q8 -----
#Agora vamos treinar o learner com os modelos ajustados
tuned_tree = makeLearner('classif.rpart', maxdepth = 4, minsplit = 10)
tuned_knn = makeLearner('classif.knn',k = 9)
#As linhas abaixo treinam o modelo no conjunto de teste (614 observações)
#com os parametros ajustados acima, em tuned_tree e tuned_knn
tree_model = train(tuned_tree, train_task)
knn_model = train(tuned_knn, train_task)
#crie uma task agora usando o conjunto 'test' em data
test_task = makeClassifTask(id = 'test_models', data = test, target='diabetes',positive = 'pos')
#A linha abaixo faz as predicoes no conjunto de teste
tree_preds = predict(tree_model,test_task)
#faca o mesmo com knn
knn_preds = predict(knn_model, test_task)
#Abaixo, mostramos a matrix de confusao para a arvore
calculateConfusionMatrix(tree_preds)
#Abaixo, mostre a matrix de confusao para o modelo com knn
calculateConfusionMatrix(knn_preds)
#8. Marque a afirmação correta:
# O modelo de knn tem maior acuracia
# O modelo de arvore apresentou mais falsos positivos
# O modelo com arvore apresentou mais falsos negativos
#9. Considere a premissa:
# "É pior afirmar que um paciente nao tem diabetes e ele ter do que dizer que ele tem e, na verdade, não ter"
# Nesse caso, a melhor técnica é:
dim(test)
dim(train)
#As linhas abaixo treinam o modelo no conjunto de teste (512 observações)
#com os parametros ajustados acima, em tuned_tree e tuned_knn
tree_model = train(tuned_tree, train_task)
knn_model = train(tuned_knn, train_task)
dim(test)
test_task
#A linha abaixo faz as predicoes no conjunto de teste
tree_preds = predict(tree_model,test_task)
#faca o mesmo com knn
knn_preds = predict(knn_model, test_task)
#Abaixo, mostramos a matrix de confusao para a arvore
calculateConfusionMatrix(tree_preds)
#Abaixo, mostre a matrix de confusao para o modelo com knn
calculateConfusionMatrix(knn_preds)
#3. Qual a mediana do número de vezes que a paciente engravidou para pacientes com diabetes e sem diabetes?
df %>% group_by(diabetes) %>% summarise(preg = median(pregnant), medAge = mean(age))
#3. Qual a mediana do número de vezes que a paciente engravidou para pacientes com diabetes e sem diabetes?
df %>% group_by(diabetes) %>% summarise(preg = median(pregnant), medAge = mean(pregnant))
#4. Quantos pacientes temos no dataset com diabetes pos e diabetes neg?
table(normdf$diabetes)
#3. Qual a mediana do número de vezes que a paciente engravidou para pacientes com diabetes e sem diabetes?
df %>% group_by(diabetes) %>% summarise(preg = median(pregnant), medAge = mean(age))
#Q4 -----
#Normalize os dados entre 0 e 1 com a função "normalizeFeatures()" do pacote mlr.
#Complete o method e range abaixo, como visto na aula 4
normdf = normalizeFeatures(df, method = "range", range = c(0,1))
head(normdf)
#4. Quantos pacientes temos no dataset com diabetes pos e diabetes neg?
table(normdf$diabetes)
#Separar em treino e teste -----
#numero de observacoes:
n_observations = nrow(normdf)
#porcentagem de observacoes para treino:
train_percent  = 2/3
#id das observacoes para treino, lembre de selecionar e executar as duas linhas abaixo juntas,
#para ter sempre o mesmo resultado
set.seed(2019)
train_id = sample(n_observations, train_percent * n_observations)
#separe em treino e teste, a funcao slice é como filter() mas usa os ids numéricos e não condicoes lógicas
train = normdf %>% slice(train_id)
test = normdf %>% slice(-train_id)
dim(train) #deve ser 614
dim(test) #deve ser 154
#4. Quantos pacientes temos no dataset com diabetes pos e diabetes neg?
table(normdf$diabetes)
#porcentagem de observacoes para treino:
train_percent  = 2/3
#id das observacoes para treino, lembre de selecionar e executar as duas linhas abaixo juntas,
#para ter sempre o mesmo resultado
set.seed(2019)
train_id = sample(n_observations, train_percent * n_observations)
#separe em treino e teste, a funcao slice é como filter() mas usa os ids numéricos e não condicoes lógicas
train = normdf %>% slice(train_id)
test = normdf %>% slice(-train_id)
dim(train) #deve ser 614
dim(test) #deve ser 154
#Q5 -----
#Crie a tarefa de classificação:
#complete os argumentos data, target e positive
#use os dados de treino separados acima
#o argumento positive deve conter a classe que queremos considerar positiva, nesse caso é a classe 'pos'
train_task = makeClassifTask(id = 'tree_vs_knn', data = train, target='diabetes',positive = 'pos')
#execute a linha abaixo para descricao da tarefa
train_task
tree_learner = makeLearner("classif.rpart")
knn_learner = makeLearner("classif.knn")
#ajuste da arvore
#vamos ajustar os hiperparametros "maxdepth" e "minsplit"
#use o limite inferior de maxdepth como 2 e superior, 5
#use o limite inferior de minsplit como 2 e superior 10
tree_ps = makeParamSet(
makeIntegerParam('maxdepth', lower = 2, upper = 5),
makeIntegerParam('minsplit', lower = 2, upper = 10))
#ajustar o k do knn
#inferiror = 3 e superior = 15
knn_ps = makeParamSet(
makeIntegerParam('k', lower = 3, upper = 15))
#estrategia de controle: 40 iteracoes com grid search
ctrl = makeTuneControlGrid(resolution = 40L)
#use cross validation com 5 folds como estrategia de amostragem
rdesc =  makeResampleDesc("CV", iters = 5)
#execute o set.seed junto com o tree_result para obert sempre o mesmo resultado
set.seed(2019)
tree_tune = tuneParams(tree_learner,
task = train_task,
resampling = rdesc,
par.set = tree_ps,
control = ctrl,
show.info=F)
tree_tune
#execute o set.seed junto com o knn_tune para obert sempre o mesmo resultado
set.seed(2019)
knn_tune = tuneParams(knn_learner,
task = train_task,
resampling = rdesc,
par.set = knn_ps,
control = ctrl,
show.info=F)
knn_tune
tree_tune = tuneParams(tree_learner,
task = train_task,
resampling = rdesc,
par.set = tree_ps,
control = ctrl,
show.info=F)
tree_tune
#execute o set.seed junto com o knn_tune para obert sempre o mesmo resultado
set.seed(2019)
knn_tune = tuneParams(knn_learner,
task = train_task,
resampling = rdesc,
par.set = knn_ps,
control = ctrl,
show.info=F)
knn_tune
#execute o set.seed junto com o tree_result para obert sempre o mesmo resultado
set.seed(2019)
tree_tune = tuneParams(tree_learner,
task = train_task,
resampling = rdesc,
par.set = tree_ps,
control = ctrl,
show.info=F)
tree_tune
#execute o set.seed junto com o knn_tune para obert sempre o mesmo resultado
set.seed(2019)
knn_tune = tuneParams(knn_learner,
task = train_task,
resampling = rdesc,
par.set = knn_ps,
control = ctrl,
show.info=F)
knn_tune
#6. A melhor combinacao de atributos para a arvore é
minsplit =
maxdepth =
#7. O melhor k para o knn é
k =
#Q8 -----
#Agora vamos treinar o learner com os modelos ajustados
tuned_tree = makeLearner('classif.rpart', maxdepth = 4, minsplit = 10)
tuned_knn = makeLearner('classif.knn',k = 9)
#As linhas abaixo treinam o modelo no conjunto de teste (614 observações)
#com os parametros ajustados acima, em tuned_tree e tuned_knn
tree_model = train(tuned_tree, train_task)
#6. A melhor combinacao de atributos para a arvore é
minsplit =
maxdepth =
#7. O melhor k para o knn é
k =
#Q8 -----
#Agora vamos treinar o learner com os modelos ajustados
tuned_tree = makeLearner('classif.rpart', maxdepth = 4, minsplit = 10)
tuned_knn = makeLearner('classif.knn',k = 9)
#As linhas abaixo treinam o modelo no conjunto de teste (614 observações)
#com os parametros ajustados acima, em tuned_tree e tuned_knn
tree_model = train(tuned_tree, train_task)
knn_model = train(tuned_knn, train_task)
#crie uma task agora usando o conjunto 'test' em data
test_task = makeClassifTask(id = 'test_models', data = test, target='diabetes',positive = 'pos')
#A linha abaixo faz as predicoes no conjunto de teste
tree_preds = predict(tree_model,test_task)
#faca o mesmo com knn
knn_preds = predict(knn_model, test_task)
#Abaixo, mostramos a matrix de confusao para a arvore
calculateConfusionMatrix(tree_preds)
#Abaixo, mostre a matrix de confusao para o modelo com knn
calculateConfusionMatrix(knn_preds)
#6. A melhor combinacao de atributos para a arvore é
minsplit =
maxdepth =
#7. O melhor k para o knn é
k =
#Q8 -----
#Agora vamos treinar o learner com os modelos ajustados
tuned_tree = makeLearner('classif.rpart', maxdepth = 4, minsplit = 10)
tuned_knn = makeLearner('classif.knn',k = 9)
#Abaixo, mostramos a matrix de confusao para a arvore
calculateConfusionMatrix(tree_preds)
#Abaixo, mostre a matrix de confusao para o modelo com knn
calculateConfusionMatrix(knn_preds)
#As linhas abaixo treinam o modelo no conjunto de teste (614 observações)
#com os parametros ajustados acima, em tuned_tree e tuned_knn
tree_model = train(tuned_tree, train_task)
knn_model = train(tuned_knn, train_task)
#crie uma task agora usando o conjunto 'test' em data
test_task = makeClassifTask(id = 'test_models', data = test, target='diabetes',positive = 'pos')
#A linha abaixo faz as predicoes no conjunto de teste
tree_preds = predict(tree_model,test_task)
#faca o mesmo com knn
knn_preds = predict(knn_model, test_task)
#Abaixo, mostramos a matrix de confusao para a arvore
calculateConfusionMatrix(tree_preds)
#Abaixo, mostre a matrix de confusao para o modelo com knn
calculateConfusionMatrix(knn_preds)
#As linhas abaixo treinam o modelo no conjunto de teste (614 observações)
#com os parametros ajustados acima, em tuned_tree e tuned_knn
tree_model = train(tuned_tree, train_task)
knn_model = train(tuned_knn, train_task)
#crie uma task agora usando o conjunto 'test' em data
test_task = makeClassifTask(id = 'test_models', data = test, target='diabetes',positive = 'pos')
#A linha abaixo faz as predicoes no conjunto de teste
tree_preds = predict(tree_model,test_task)
#faca o mesmo com knn
knn_preds = predict(knn_model, test_task)
#Abaixo, mostramos a matrix de confusao para a arvore
calculateConfusionMatrix(tree_preds)
#Abaixo, mostre a matrix de confusao para o modelo com knn
calculateConfusionMatrix(knn_preds)
library(tidyverse)
library(mlr)
library(mlbench)
library(rpart)
library(rpart.plot)
#Carregue o conjunto de dados
data(PimaIndiansDiabetes)
df = PimaIndiansDiabetes
#use ?PimaIndiansDiabetes
#execute a linha abaixo para ver a descrição do conjunto de dados
?PimaIndiansDiabetes
# Verifique as dimensões e as primeiras linhas
dim(df)
head(df)
#vamos comparar o desempenho de árvores de decisão vs knn para prever
#se o paciente tem diabetes ou não
#1. Esta é uma tarefa de classificação ou regressão?
#2. Quantos atributos preditores vamos usar?
#3. Qual a mediana do número de vezes que a paciente engravidou para pacientes com diabetes e sem diabetes?
df %>% group_by(diabetes) %>% summarise(preg = median(pregnant), medAge = mean(age))
#Q4 -----
#Normalize os dados entre 0 e 1 com a função "normalizeFeatures()" do pacote mlr.
#Complete o method e range abaixo, como visto na aula 4
normdf = normalizeFeatures(df, method = "range", range = c(0,1))
head(normdf)
#4. Quantos pacientes temos no dataset com diabetes pos e diabetes neg?
table(normdf$diabetes)
#Separar em treino e teste -----
#numero de observacoes:
n_observations = nrow(normdf)
#porcentagem de observacoes para treino:
train_percent  = 2/3
#id das observacoes para treino, lembre de selecionar e executar as duas linhas abaixo juntas,
#para ter sempre o mesmo resultado
set.seed(2019)
train_id = sample(n_observations, train_percent * n_observations)
#separe em treino e teste, a funcao slice é como filter() mas usa os ids numéricos e não condicoes lógicas
train = normdf %>% slice(train_id)
test = normdf %>% slice(-train_id)
dim(train) #deve ser 614
dim(test) #deve ser 154
#Q5 -----
#Crie a tarefa de classificação:
#complete os argumentos data, target e positive
#use os dados de treino separados acima
#o argumento positive deve conter a classe que queremos considerar positiva, nesse caso é a classe 'pos'
train_task = makeClassifTask(id = 'tree_vs_knn', data = train, target='diabetes',positive = 'pos')
#execute a linha abaixo para descricao da tarefa
train_task
#5.Marque as alternativas corretas:
# 8 colunas do conjunto de dados são numericas
# A variavel meta é binária
# A quantidade de pacientes com diabetes é menos de 50% do que a quantidade de não diabéticos no conjunto de treino
# Nenhuma coluna do conjunto de dados é um fator
#Q6 e Q7 ----
#Crie um learner para árvore e outro para knn usando os
#classif das aulas 3 e 4, respectivamente
tree_learner = makeLearner("classif.rpart")
knn_learner = makeLearner("classif.knn")
#ajuste da arvore
#vamos ajustar os hiperparametros "maxdepth" e "minsplit"
#use o limite inferior de maxdepth como 2 e superior, 5
#use o limite inferior de minsplit como 2 e superior 10
tree_ps = makeParamSet(
makeIntegerParam('maxdepth', lower = 2, upper = 5),
makeIntegerParam('minsplit', lower = 2, upper = 10))
#ajustar o k do knn
#inferiror = 3 e superior = 15
knn_ps = makeParamSet(
makeIntegerParam('k', lower = 3, upper = 15))
#estrategia de controle: 40 iteracoes com grid search
ctrl = makeTuneControlGrid(resolution = 40L)
#use cross validation com 5 folds como estrategia de amostragem
rdesc =  makeResampleDesc("CV", iters = 5)
#execute o set.seed junto com o tree_result para obert sempre o mesmo resultado
set.seed(2019)
tree_tune = tuneParams(tree_learner,
task = train_task,
resampling = rdesc,
par.set = tree_ps,
control = ctrl,
show.info=F)
tree_tune
#execute o set.seed junto com o knn_tune para obert sempre o mesmo resultado
set.seed(2019)
knn_tune = tuneParams(knn_learner,
task = train_task,
resampling = rdesc,
par.set = knn_ps,
control = ctrl,
show.info=F)
knn_tune
#6. A melhor combinacao de atributos para a arvore é
minsplit =
maxdepth =
#7. O melhor k para o knn é
k =
#Q8 -----
#Agora vamos treinar o learner com os modelos ajustados
tuned_tree = makeLearner('classif.rpart', maxdepth = 4, minsplit = 10)
tuned_knn = makeLearner('classif.knn',k = 9)
#As linhas abaixo treinam o modelo no conjunto de teste (614 observações)
#com os parametros ajustados acima, em tuned_tree e tuned_knn
tree_model = train(tuned_tree, train_task)
knn_model = train(tuned_knn, train_task)
#crie uma task agora usando o conjunto 'test' em data
test_task = makeClassifTask(id = 'test_models', data = test, target='diabetes',positive = 'pos')
#A linha abaixo faz as predicoes no conjunto de teste
tree_preds = predict(tree_model,test_task)
#faca o mesmo com knn
knn_preds = predict(knn_model, test_task)
#Abaixo, mostramos a matrix de confusao para a arvore
calculateConfusionMatrix(tree_preds)
#Abaixo, mostre a matrix de confusao para o modelo com knn
calculateConfusionMatrix(knn_preds)
#8. Marque a afirmação correta:
# O modelo de knn tem maior acuracia
# O modelo de arvore apresentou mais falsos positivos
# O modelo com arvore apresentou mais falsos negativos
#9. Considere a premissa:
# "É pior afirmar que um paciente nao tem diabetes e ele ter do que dizer que ele tem e, na verdade, não ter"
# Nesse caso, a melhor técnica é:
